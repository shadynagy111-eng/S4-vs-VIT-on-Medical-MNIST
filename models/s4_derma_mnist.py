# -*- coding: utf-8 -*-
"""s4-derma-mnist.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hP5fHvRObiKYtOa0mXhlPCy_lMriwRsl
"""

!git clone https://github.com/state-spaces/s4.git

# Commented out IPython magic to ensure Python compatibility.
# %cd /kaggle/working/s4

!pip install -r requirements.txt

!pip install s4

!pip install -r requirements-dev.txt

import s4

!pip install medmnist

s4.VERSION

# Commented out IPython magic to ensure Python compatibility.
# %cd /kaggle/working/s4

!pip uninstall torch torchvision torchaudio torchtext -y

!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
!pip install torchtext --upgrade

# Commented out IPython magic to ensure Python compatibility.
# %cd /kaggle/working/s4

# !python -m example.py

!nvidia-smi

import torch
import torch.nn as nn
import torch.optim as optim
import torch.backends.cudnn as cudnn

import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, TensorDataset
import os
import argparse
import numpy as np
import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings("ignore")

import s4

from models.s4.s4 import S4Block as S4  # Can use full version instead of minimal S4D standalone below
from models.s4.s4d import S4D
from tqdm.auto import tqdm

# Dropout broke in PyTorch 1.11
if tuple(map(int, torch.__version__.split('.')[:2])) == (1, 11):
    print("WARNING: Dropout is bugged in PyTorch 1.11. Results may be worse.")
    dropout_fn = nn.Dropout
if tuple(map(int, torch.__version__.split('.')[:2])) >= (1, 12):
    dropout_fn = nn.Dropout1d
else:
    dropout_fn = nn.Dropout2d


parser = argparse.ArgumentParser(description='MedMNIST Training')
# Optimizer
parser.add_argument('--lr', default=0.001, type=float, help='Learning rate')
parser.add_argument('--weight_decay', default=0.01, type=float, help='Weight decay')
# Scheduler
# parser.add_argument('--patience', default=10, type=float, help='Patience for learning rate scheduler')
parser.add_argument('--epochs', default=5, type=float, help='Training epochs')


# Dataset
#parser.add_argument('--dataset', default='cifar10', choices=['mnist', 'cifar10'], type=str, help='Dataset')
#parser.add_argument('--grayscale', action='store_true', help='Use grayscale CIFAR10')
# Dataloader
parser.add_argument('--num_workers', default=4, type=int, help='Number of workers to use for dataloader')
parser.add_argument('--batch_size', default=64, type=int, help='Batch size')


# Model
parser.add_argument('--n_layers', default=4, type=int, help='Number of layers')
parser.add_argument('--d_model', default=256, type=int, help='Model dimension')
parser.add_argument('--dropout', default=0.1, type=float, help='Dropout')
parser.add_argument('--prenorm', action='store_true', help='Prenorm')


# General
parser.add_argument('--resume', '-r', action='store_true', help='Resume from checkpoint')

args = parser.parse_args([])

device = 'cuda' if torch.cuda.is_available() else 'cpu'
best_acc = 0  # best test accuracy
start_epoch = 0  # start from epoch 0 or last checkpoint epoch

!python -m medmnist available

from medmnist import DermaMNIST
train_dataset = DermaMNIST(split="train", download=True)

train_dataset

validation_dataset = DermaMNIST(split="val", download=True)
validation_dataset

test_dataset = DermaMNIST(split="test", download=True)
test_dataset
BATCH_SIZE = 128

test_dataset.imgs.shape

train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)
validadtion_loader = DataLoader(dataset=validation_dataset, batch_size=2*BATCH_SIZE, shuffle=False)
test_loader = DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)

class S4Model(nn.Module):

    def __init__(
        self,
        d_input=3,
        d_output=7,
        d_model=256,
        n_layers=8,
        dropout=0.2,
        prenorm=False,
    ):
        super().__init__()

        self.prenorm = prenorm

        # Linear encoder (d_input = 1 for grayscale and 3 for RGB)
        self.encoder = nn.Linear(d_input, d_model)

        # Stack S4 layers as residual blocks
        self.s4_layers = nn.ModuleList()
        self.norms = nn.ModuleList()
        self.dropouts = nn.ModuleList()
        for _ in range(n_layers):
            self.s4_layers.append(
                S4D(d_model, dropout=dropout, transposed=True, lr=min(0.001, args.lr))
            )
            self.norms.append(nn.LayerNorm(d_model))
            self.dropouts.append(dropout_fn(dropout))

        # Linear decoder
        self.decoder = nn.Linear(d_model, d_output)

    def forward(self, x):
        """
        Input x is shape (B, L, d_input)
        """
        x = self.encoder(x)  # (B, L, d_input) -> (B, L, d_model)

        x = x.transpose(-1, -2)  # (B, L, d_model) -> (B, d_model, L)
        for layer, norm, dropout in zip(self.s4_layers, self.norms, self.dropouts):
            # Each iteration of this loop will map (B, d_model, L) -> (B, d_model, L)

            z = x
            if self.prenorm:
                # Prenorm
                z = norm(z.transpose(-1, -2)).transpose(-1, -2)

            # Apply S4 block: we ignore the state input and output
            z, _ = layer(z)

            # Dropout on the output of the S4 block
            z = dropout(z)

            # Residual connection
            x = z + x

            if not self.prenorm:
                # Postnorm
                x = norm(x.transpose(-1, -2)).transpose(-1, -2)

        x = x.transpose(-1, -2)

        # Pooling: average pooling over the sequence length
        x = x.mean(dim=1)

        # Decode the outputs
        x = self.decoder(x)  # (B, d_model) -> (B, d_output)

        return x

# Model
print('==> Building model..')
model = S4Model(
    d_input=3,
    d_output=7,
    d_model=args.d_model,
    n_layers=args.n_layers,
    dropout=args.dropout,
    prenorm=args.prenorm,
)

model = model.to(device)
if device == 'cuda':
    cudnn.benchmark = True

if args.resume:
    # Load checkpoint.
    print('==> Resuming from checkpoint..')
    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'
    checkpoint = torch.load('./checkpoint/ckpt.pth')
    model.load_state_dict(checkpoint['model'])
    best_acc = checkpoint['acc']
    start_epoch = checkpoint['epoch']

# Optimizer

def setup_optimizer(model, lr, weight_decay, epochs):
    """
    S4 requires a specific optimizer setup.

    The S4 layer (A, B, C, dt) parameters typically
    require a smaller learning rate (typically 0.001), with no weight decay.

    The rest of the model can be trained with a higher learning rate (e.g. 0.004, 0.01)
    and weight decay (if desired).
    """

    # All parameters in the model
    all_parameters = list(model.parameters())

    # General parameters don't contain the special _optim key
    params = [p for p in all_parameters if not hasattr(p, "_optim")]

    # Create an optimizer with the general parameters
    optimizer = optim.AdamW(params, lr=lr, weight_decay=weight_decay)

    # Add parameters with special hyperparameters
    hps = [getattr(p, "_optim") for p in all_parameters if hasattr(p, "_optim")]
    hps = [
        dict(s) for s in sorted(list(dict.fromkeys(frozenset(hp.items()) for hp in hps)))
    ]  # Unique dicts
    for hp in hps:
        params = [p for p in all_parameters if getattr(p, "_optim", None) == hp]
        optimizer.add_param_group(
            {"params": params, **hp}
        )

    # Create a lr scheduler
    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=patience, factor=0.2)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)

    # Print optimizer info
    keys = sorted(set([k for hp in hps for k in hp.keys()]))
    for i, g in enumerate(optimizer.param_groups):
        group_hps = {k: g.get(k, None) for k in keys}
        print(' | '.join([
            f"Optimizer group {i}",
            f"{len(g['params'])} tensors",
        ] + [f"{k} {v}" for k, v in group_hps.items()]))

    return optimizer, scheduler

criterion = nn.CrossEntropyLoss()
optimizer, scheduler = setup_optimizer(
    model, lr=args.lr, weight_decay=args.weight_decay, epochs=args.epochs
)

train_dataset.montage(length=50)

train_dataset.imgs[0].shape

import torch
from torch.utils.data import TensorDataset, DataLoader
from torchvision import transforms

# 1. Define the correct transform
# ToTensor() takes (28, 28) and makes it (1, 28, 28)
# permute(1, 2, 0) moves the '1' to the end -> (28, 28, 1)
transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
            transforms.Lambda(lambda x: x.view(3, 784).t())
        ])

# 2. Fix the "Not Callable" Error
# Assuming train_dataset.imgs is your data (numpy array)
# and train_dataset.labels is your target.
# You must apply transforms MANUALLY if your dataset isn't a Torchvision object.

def apply_transforms(data, transform_func):
    # This converts each image in your numpy array using your pipeline
    return torch.stack([transform_func(img) for img in data])

# Transform the raw data
train_data_transformed = apply_transforms(train_dataset.imgs, transform)
val_data_transformed = apply_transforms(validation_dataset.imgs, transform)
test_data_transformed=apply_transforms(test_dataset.imgs,transform)

# 3. Create the actual Dataset objects
train_set = TensorDataset(train_data_transformed, torch.tensor(train_dataset.labels))
validation_set = TensorDataset(val_data_transformed, torch.tensor(validation_dataset.labels))
test_set=TensorDataset(test_data_transformed,torch.tensor(test_dataset.labels))

# 4. Create DataLoaders
train_loader = DataLoader(train_set, batch_size=32, shuffle=True)
val_loader = DataLoader(validation_set, batch_size=32, shuffle=False)
test_loader=DataLoader(test_set,batch_size=32,shuffle=False)

!mkdir /kaggle/working/checkpoint

# Training
def train():
    model.train()
    train_loss = 0
    correct = 0
    total = 0
    pbar = tqdm(enumerate(train_loader))
    for batch_idx, (inputs, targets) in pbar:
        inputs, targets = inputs.to(device), targets.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)

        # Loss needs 1D targets
        # Weights based on DermaMNIST class counts (approximate)
# Give more weight to rare classes, less to the majority
        weights = torch.tensor([5.0, 5.0, 2.0, 10.0, 0.5, 1.0, 8.0]).to(device)
        criterion = torch.nn.CrossEntropyLoss(weight=weights)
        loss = criterion(outputs, targets.squeeze().long())
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        _, predicted = outputs.max(1)

        total += targets.size(0)

        # FIX: Squeeze targets here to prevent broadcasting!
        correct += predicted.eq(targets.squeeze()).sum().item()

        pbar.set_description(
            'Batch Idx: (%d/%d) | Loss: %.3f | Acc: %.3f%% (%d/%d)' %
            (batch_idx, len(train_loader), train_loss/(batch_idx+1),
             100.*correct/total, correct, total)
        )
    # CRITICAL: Return the values to the loop
    avg_loss = train_loss / len(train_loader)
    acc = 100. * correct / total
    return avg_loss, acc

def eval(epoch, val_loader,criterion, checkpoint=False):
    global best_acc
    model.eval()
    eval_loss = 0
    correct = 0
    total = 0

    with torch.no_grad():
        pbar = tqdm(enumerate(val_loader), total=len(val_loader))
        for batch_idx, (inputs, targets) in pbar:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, targets.squeeze().long())

            weights = torch.tensor([5.0, 5.0, 2.0, 10.0, 0.5, 1.0, 8.0]).to(device)
            criterion = torch.nn.CrossEntropyLoss(weight=weights)
            eval_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets.squeeze()).sum().item()

            pbar.set_description(
                'Batch Idx: (%d/%d) | Loss: %.3f | Acc: %.3f%%' %
                (batch_idx, len(val_loader), eval_loss/(batch_idx+1), 100.*correct/total)
            )

    avg_loss = eval_loss / len(val_loader)
    acc = 100. * correct / total

    # --- CHECKPOINT LOGIC (Must be BEFORE the final return) ---
    if checkpoint:
        if acc > best_acc:
            print(f'-- Saving Checkpoint... Accuracy: {acc:.2f}% --')
            state = {
                'model': model.state_dict(),
                'acc': acc,
                'epoch': epoch,
            }
            # Use Absolute Paths for Kaggle
            if not os.path.isdir('/kaggle/working/checkpoint'):
                os.makedirs('/kaggle/working/checkpoint')

            torch.save(state, '/kaggle/working/checkpoint/ckpt.pth')
            best_acc = acc

    return avg_loss, acc # <--- The exit door is now at the very end

pbar = tqdm(range(start_epoch, args.epochs))
val_acc = 0
for epoch in pbar:
    if epoch == 0:
        pbar.set_description('Epoch: %d' % (epoch))
    else:
        pbar.set_description('Epoch: %d | Val acc: %1.3f' % (epoch, val_acc))
    train()
    val_loss,val_acc = eval(epoch, val_loader, criterion,checkpoint=True)
    eval(epoch, test_loader,criterion)
    scheduler.step()
    print(f"Epoch {epoch} learning rate: {scheduler.get_last_lr()}")

!find /kaggle/working -name "*.pth"

import torch
import numpy as np
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

def evaluate_and_plot_cm(model, test_loader, checkpoint_path, device):
    # 1. Load the checkpoint
    print(f"Loading checkpoint from {checkpoint_path}...")
    checkpoint = torch.load(checkpoint_path)
    model.load_state_dict(checkpoint['model'])
    model.to(device)
    model.eval()

    all_preds = []
    all_targets = []

    # 2. Run Inference
    with torch.no_grad():
        for inputs, targets in test_loader:
            inputs = inputs.to(device)
            # Ensure row-by-row shape [Batch, 28, 28]
            outputs = model(inputs)

            # If your S4 model returns (output, state), unpack it:
            if isinstance(outputs, tuple):
                outputs = outputs[0]

            _, predicted = outputs.max(1)

            all_preds.extend(predicted.cpu().numpy())
            all_targets.extend(targets.cpu().numpy())

    # 3. Compute Confusion Matrix
    cm = confusion_matrix(all_targets, all_preds)
    return all_targets, all_preds, cm

# --- EXECUTION ---
ckpath='/kaggle/working/checkpoint/ckpt.pth'
targets, preds, cm = evaluate_and_plot_cm(model, test_loader,ckpath, device)

cm



import seaborn as sns
sns.heatmap(cm,annot=True,fmt='d',cmap='Blues')

def count_parameters(model):
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in model.parameters())

    print(f'Total Parameters: {total_params:,}')
    print(f'Trainable Parameters: {trainable_params:,}')
    return trainable_params

count_parameters(model)

from torchinfo import summary

# row-by-row input: (batch_size, sequence_length, d_input)
summary(model, input_size=(1, 4096, 3))

# Lists to store metrics
history = {
    'train_loss': [], 'val_loss': [],
    'train_acc': [], 'val_acc': []
}

num_epochs = 5

for epoch in range(num_epochs):
    # Now these functions return (loss, acc) instead of None!
    t_loss, t_acc = train()
    v_loss, v_acc = eval(epoch, val_loader,criterion,checkpoint=True)

    history['train_loss'].append(t_loss)
    history['val_loss'].append(v_loss)
    history['train_acc'].append(t_acc)
    history['val_acc'].append(v_acc)

    print(f"\n[Epoch {epoch}] Train Loss: {t_loss:.4f} | Train Acc: {t_acc:.2f}%")
    print(f"[Epoch {epoch}] Val Loss: {v_loss:.4f} | Val Acc: {v_acc:.2f}%\n")

def plot_training_history(history):
    epochs = range(1, len(history['train_loss']) + 1)

    plt.figure(figsize=(14, 5))

    # Plot 1: Loss
    plt.subplot(1, 2, 1)
    plt.plot(epochs, history['train_loss'], 'b-o', label='Training Loss')
    plt.plot(epochs, history['val_loss'], 'r-o', label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    # Plot 2: Accuracy
    plt.subplot(1, 2, 2)
    plt.plot(epochs, history['train_acc'], 'b-s', label='Training Acc')
    plt.plot(epochs, history['val_acc'], 'r-s', label='Validation Acc')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy (%)')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

plot_training_history(history)

"""**1. Throughput (Samples per Second)**

This measures how fast the model processes data. S4 is often faster than ViT on long sequences because it can be computed as a convolution.
"""

import time

def measure_throughput(model, loader, device):
    model.eval()
    start_time = time.time()
    total_samples = 0

    with torch.no_grad():
        for inputs, _ in loader:
            inputs = inputs.to(device)
            _ = model(inputs)
            total_samples += inputs.size(0)

    end_time = time.time()
    throughput = total_samples / (end_time - start_time)
    print(f"Throughput: {throughput:.2f} samples/sec")
    return throughput

measure_throughput(model,train_loader,device)

"""**2. Parameter Efficiency (Accuracy vs. Model Size)**"""

def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

print(f"Total Trainable Params: {count_parameters(model):,}")

"""**3. GPU Memory Utilization**

Transformers store large "attention maps," which consume huge amounts of VRAM. S4 uses a recurrent/convolutional state, which is much leaner.
"""

# Run this after a few batches
memory_used = torch.cuda.max_memory_allocated() / (1024 ** 2) # Convert to MB
print(f"Peak GPU Memory: {memory_used:.2f} MB")